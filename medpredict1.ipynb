{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPP5/X16+RxUZXLhKUNOkvo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagken/medpredictml/blob/main/medpredict1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9b2eEZLT9zGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ec6d86-500d-4b90-b042-4f121cd50b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age admission_type     diagnosis medications  length_of_stay  \\\n",
            "0   45      emergency      diabetes     insulin               5   \n",
            "1   60        routine  hypertension   metformin               3   \n",
            "2   30         urgent        asthma   albuterol               2   \n",
            "\n",
            "   previous_admissions  readmitted  \n",
            "0                    2           1  \n",
            "1                    1           0  \n",
            "2                    0           1  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/nagken/medpredictml/main/data/patient_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(df.head())  # Confirm it's correct\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Diabetic Data\n",
        "diabetic_url = \"https://raw.githubusercontent.com/nagken/medpredictml/main/data/diabetic_data.csv\"\n",
        "df_diabetic = pd.read_csv(diabetic_url)\n",
        "\n",
        "# Load Patient Data\n",
        "patient_url = \"https://raw.githubusercontent.com/nagken/medpredictml/main/data/patient_data.csv\"\n",
        "df_patient = pd.read_csv(patient_url)\n",
        "\n",
        "# Display first few rows\n",
        "print(\"Diabetic Data Sample:\")\n",
        "print(df_diabetic.head())\n",
        "\n",
        "print(\"\\nPatient Data Sample:\")\n",
        "print(df_patient.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdSVdn3-PrdH",
        "outputId": "c1265e9c-76f1-4925-90dd-b27e5a171d83"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diabetic Data Sample:\n",
            "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
            "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
            "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
            "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
            "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
            "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
            "\n",
            "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
            "0                  6                        25                    1   \n",
            "1                  1                         1                    7   \n",
            "2                  1                         1                    7   \n",
            "3                  1                         1                    7   \n",
            "4                  1                         1                    7   \n",
            "\n",
            "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
            "0                 1  ...          No      No                   No   \n",
            "1                 3  ...          No      Up                   No   \n",
            "2                 2  ...          No      No                   No   \n",
            "3                 2  ...          No      Up                   No   \n",
            "4                 1  ...          No  Steady                   No   \n",
            "\n",
            "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
            "0                   No                        No                       No   \n",
            "1                   No                        No                       No   \n",
            "2                   No                        No                       No   \n",
            "3                   No                        No                       No   \n",
            "4                   No                        No                       No   \n",
            "\n",
            "   metformin-pioglitazone  change diabetesMed readmitted  \n",
            "0                      No      No          No         NO  \n",
            "1                      No      Ch         Yes        >30  \n",
            "2                      No      No         Yes         NO  \n",
            "3                      No      Ch         Yes         NO  \n",
            "4                      No      Ch         Yes         NO  \n",
            "\n",
            "[5 rows x 50 columns]\n",
            "\n",
            "Patient Data Sample:\n",
            "   age admission_type     diagnosis medications  length_of_stay  \\\n",
            "0   45      emergency      diabetes     insulin               5   \n",
            "1   60        routine  hypertension   metformin               3   \n",
            "2   30         urgent        asthma   albuterol               2   \n",
            "\n",
            "   previous_admissions  readmitted  \n",
            "0                    2           1  \n",
            "1                    1           0  \n",
            "2                    0           1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check column names and missing values\n",
        "print(\"\\nDiabetic Data Info:\")\n",
        "print(df_diabetic.info())\n",
        "\n",
        "print(\"\\nPatient Data Info:\")\n",
        "print(df_patient.info())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values in Diabetic Data:\")\n",
        "print(df_diabetic.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing Values in Patient Data:\")\n",
        "print(df_patient.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbATQY3sNvZB",
        "outputId": "fe52d30b-b4f7-44bb-fa9e-4b5d827f25c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Diabetic Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 101766 entries, 0 to 101765\n",
            "Data columns (total 50 columns):\n",
            " #   Column                    Non-Null Count   Dtype \n",
            "---  ------                    --------------   ----- \n",
            " 0   encounter_id              101766 non-null  int64 \n",
            " 1   patient_nbr               101766 non-null  int64 \n",
            " 2   race                      101766 non-null  object\n",
            " 3   gender                    101766 non-null  object\n",
            " 4   age                       101766 non-null  object\n",
            " 5   weight                    101766 non-null  object\n",
            " 6   admission_type_id         101766 non-null  int64 \n",
            " 7   discharge_disposition_id  101766 non-null  int64 \n",
            " 8   admission_source_id       101766 non-null  int64 \n",
            " 9   time_in_hospital          101766 non-null  int64 \n",
            " 10  payer_code                101766 non-null  object\n",
            " 11  medical_specialty         101766 non-null  object\n",
            " 12  num_lab_procedures        101766 non-null  int64 \n",
            " 13  num_procedures            101766 non-null  int64 \n",
            " 14  num_medications           101766 non-null  int64 \n",
            " 15  number_outpatient         101766 non-null  int64 \n",
            " 16  number_emergency          101766 non-null  int64 \n",
            " 17  number_inpatient          101766 non-null  int64 \n",
            " 18  diag_1                    101766 non-null  object\n",
            " 19  diag_2                    101766 non-null  object\n",
            " 20  diag_3                    101766 non-null  object\n",
            " 21  number_diagnoses          101766 non-null  int64 \n",
            " 22  max_glu_serum             5346 non-null    object\n",
            " 23  A1Cresult                 17018 non-null   object\n",
            " 24  metformin                 101766 non-null  object\n",
            " 25  repaglinide               101766 non-null  object\n",
            " 26  nateglinide               101766 non-null  object\n",
            " 27  chlorpropamide            101766 non-null  object\n",
            " 28  glimepiride               101766 non-null  object\n",
            " 29  acetohexamide             101766 non-null  object\n",
            " 30  glipizide                 101766 non-null  object\n",
            " 31  glyburide                 101766 non-null  object\n",
            " 32  tolbutamide               101766 non-null  object\n",
            " 33  pioglitazone              101766 non-null  object\n",
            " 34  rosiglitazone             101766 non-null  object\n",
            " 35  acarbose                  101766 non-null  object\n",
            " 36  miglitol                  101766 non-null  object\n",
            " 37  troglitazone              101766 non-null  object\n",
            " 38  tolazamide                101766 non-null  object\n",
            " 39  examide                   101766 non-null  object\n",
            " 40  citoglipton               101766 non-null  object\n",
            " 41  insulin                   101766 non-null  object\n",
            " 42  glyburide-metformin       101766 non-null  object\n",
            " 43  glipizide-metformin       101766 non-null  object\n",
            " 44  glimepiride-pioglitazone  101766 non-null  object\n",
            " 45  metformin-rosiglitazone   101766 non-null  object\n",
            " 46  metformin-pioglitazone    101766 non-null  object\n",
            " 47  change                    101766 non-null  object\n",
            " 48  diabetesMed               101766 non-null  object\n",
            " 49  readmitted                101766 non-null  object\n",
            "dtypes: int64(13), object(37)\n",
            "memory usage: 38.8+ MB\n",
            "None\n",
            "\n",
            "Patient Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3 entries, 0 to 2\n",
            "Data columns (total 7 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   age                  3 non-null      int64 \n",
            " 1   admission_type       3 non-null      object\n",
            " 2   diagnosis            3 non-null      object\n",
            " 3   medications          3 non-null      object\n",
            " 4   length_of_stay       3 non-null      int64 \n",
            " 5   previous_admissions  3 non-null      int64 \n",
            " 6   readmitted           3 non-null      int64 \n",
            "dtypes: int64(4), object(3)\n",
            "memory usage: 300.0+ bytes\n",
            "None\n",
            "\n",
            "Missing Values in Diabetic Data:\n",
            "encounter_id                    0\n",
            "patient_nbr                     0\n",
            "race                            0\n",
            "gender                          0\n",
            "age                             0\n",
            "weight                          0\n",
            "admission_type_id               0\n",
            "discharge_disposition_id        0\n",
            "admission_source_id             0\n",
            "time_in_hospital                0\n",
            "payer_code                      0\n",
            "medical_specialty               0\n",
            "num_lab_procedures              0\n",
            "num_procedures                  0\n",
            "num_medications                 0\n",
            "number_outpatient               0\n",
            "number_emergency                0\n",
            "number_inpatient                0\n",
            "diag_1                          0\n",
            "diag_2                          0\n",
            "diag_3                          0\n",
            "number_diagnoses                0\n",
            "max_glu_serum               96420\n",
            "A1Cresult                   84748\n",
            "metformin                       0\n",
            "repaglinide                     0\n",
            "nateglinide                     0\n",
            "chlorpropamide                  0\n",
            "glimepiride                     0\n",
            "acetohexamide                   0\n",
            "glipizide                       0\n",
            "glyburide                       0\n",
            "tolbutamide                     0\n",
            "pioglitazone                    0\n",
            "rosiglitazone                   0\n",
            "acarbose                        0\n",
            "miglitol                        0\n",
            "troglitazone                    0\n",
            "tolazamide                      0\n",
            "examide                         0\n",
            "citoglipton                     0\n",
            "insulin                         0\n",
            "glyburide-metformin             0\n",
            "glipizide-metformin             0\n",
            "glimepiride-pioglitazone        0\n",
            "metformin-rosiglitazone         0\n",
            "metformin-pioglitazone          0\n",
            "change                          0\n",
            "diabetesMed                     0\n",
            "readmitted                      0\n",
            "dtype: int64\n",
            "\n",
            "Missing Values in Patient Data:\n",
            "age                    0\n",
            "admission_type         0\n",
            "diagnosis              0\n",
            "medications            0\n",
            "length_of_stay         0\n",
            "previous_admissions    0\n",
            "readmitted             0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Selecting categorical columns from Patient Data\n",
        "categorical_cols = [\"admission_type\", \"diagnosis\", \"medications\"]\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "\n",
        "# Encoding categorical variables\n",
        "encoded_features = encoder.fit_transform(df_patient[categorical_cols])\n",
        "encoded_df = pd.DataFrame(encoded_features)\n",
        "\n",
        "# Concatenating with original dataset\n",
        "df_patient_processed = pd.concat([df_patient.drop(columns=categorical_cols), encoded_df], axis=1)\n",
        "\n",
        "print(\"\\nProcessed Patient Data Sample:\")\n",
        "print(df_patient_processed.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNwmDLtVP_Qy",
        "outputId": "3e864401-3867-4402-cb6d-6ad9ff635404"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed Patient Data Sample:\n",
            "   age  length_of_stay  previous_admissions  readmitted    0    1    2    3  \\\n",
            "0   45               5                    2           1  1.0  0.0  0.0  0.0   \n",
            "1   60               3                    1           0  0.0  1.0  0.0  0.0   \n",
            "2   30               2                    0           1  0.0  0.0  1.0  1.0   \n",
            "\n",
            "     4    5    6    7    8  \n",
            "0  1.0  0.0  0.0  1.0  0.0  \n",
            "1  0.0  1.0  0.0  0.0  1.0  \n",
            "2  0.0  0.0  1.0  0.0  0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define features and target variable\n",
        "X = df_patient_processed.drop(columns=[\"readmitted\"])  # Assuming 'readmitted' is the target column\n",
        "y = df_patient_processed[\"readmitted\"]\n",
        "\n",
        "# Split data into train-test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an XGBoost model\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Check accuracy\n",
        "print(\"\\nModel Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipn0HSyyQEPO",
        "outputId": "23a08321-9edc-4432-afe1-c2574c2433d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:54:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_patient_processed[\"readmitted\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1KV32SUQfad",
        "outputId": "0036bebc-cd5d-4455-fc5a-797ad5a6980f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "readmitted\n",
            "1    2\n",
            "0    1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_patient_processed[\"readmitted\"].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mFiWGX9QmEE",
        "outputId": "650e3e81-4219-4ebe-b0a9-68978fe19734"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_patient_processed[\"readmitted\"] = df_patient_processed[\"readmitted\"].map({\"<30\": 1, \">30\": 1, \"NO\": 0})\n"
      ],
      "metadata": {
        "id": "4e4En-BtQoSv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRdaQaxWQqw0",
        "outputId": "ceef558d-dc46-4e76-e768-e0f9aa765880"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age                      int64\n",
            "length_of_stay           int64\n",
            "previous_admissions      int64\n",
            "0                      float64\n",
            "1                      float64\n",
            "2                      float64\n",
            "3                      float64\n",
            "4                      float64\n",
            "5                      float64\n",
            "6                      float64\n",
            "7                      float64\n",
            "8                      float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define features and target variable\n",
        "X = df_patient_processed.drop(columns=[\"readmitted\"])\n",
        "y = df_patient_processed[\"readmitted\"]\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Train XGBoost with scale_pos_weight\n",
        "model = XGBClassifier(eval_metric='logloss', scale_pos_weight=y_train.value_counts()[0] / y_train.value_counts()[1])\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"\\nFixed Model Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "MBtdNjwhQsrH",
        "outputId": "adaa7bc0-1e22-40c4-e0a6-6b2768b73688"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input y contains NaN.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-14432ddff973>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Split into training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Train XGBoost with scale_pos_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2870\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2872\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_common_namespace_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2403\u001b[0m                 \u001b[0mUserWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2404\u001b[0m             )\n\u001b[0;32m-> 2405\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.isnull().sum())  # Check how many NaNs exist\n",
        "print(y.unique())        # Check all unique values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLqqSNegQ4dQ",
        "outputId": "747d1faf-1b91-4cf3-e059-0d29023d5701"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "[nan]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_patient_processed = df_patient_processed.dropna(subset=[\"readmitted\"])\n",
        "X = df_patient_processed.drop(columns=[\"readmitted\"])\n",
        "y = df_patient_processed[\"readmitted\"]\n"
      ],
      "metadata": {
        "id": "H73Py9a4Q6UZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_patient_processed[\"readmitted\"].fillna(df_patient_processed[\"readmitted\"].mode()[0], inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "jO5-zMXRQ8zW",
        "outputId": "98ee1d31-a4b2-47c4-97c4-e0512d629ab4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 0 is not in range",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3a39eb4515b0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_patient_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"readmitted\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_patient_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"readmitted\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.isnull().sum())  # Should print 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wusxmmdLQ-uz",
        "outputId": "141ffddf-d89d-4e7e-ffeb-256ab2afed7a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/nagken/medpredictml/main/data/patient_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 🔍 Step 1: Check for missing values\n",
        "print(\"Missing values in each column:\\n\", df.isnull().sum())\n",
        "\n",
        "# 🔍 Step 2: Handle missing values (Drop or Impute)\n",
        "df = df.dropna(subset=[\"readmitted\"])  # Drop rows with missing target variable\n",
        "\n",
        "# 🔍 Step 3: Feature Engineering - Convert categorical variables\n",
        "categorical_cols = [\"admission_type\", \"diagnosis\", \"medications\"]\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "encoded_features = encoder.fit_transform(df[categorical_cols])\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out())\n",
        "\n",
        "# 🔍 Step 4: Standardize numerical features\n",
        "numerical_cols = [\"age\", \"length_of_stay\", \"previous_admissions\"]\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(df[numerical_cols])\n",
        "scaled_df = pd.DataFrame(scaled_features, columns=numerical_cols)\n",
        "\n",
        "# 🔍 Step 5: Prepare final dataset\n",
        "X = pd.concat([scaled_df, encoded_df], axis=1)\n",
        "y = df[\"readmitted\"].astype(int)  # Convert target variable to integer\n",
        "\n",
        "# 🔍 Step 6: Train-Test Split (Fix NaN issues in `y`)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 🔍 Step 7: Train XGBoost Model\n",
        "model = XGBClassifier(eval_metric='logloss', scale_pos_weight=y_train.value_counts()[0] / y_train.value_counts()[1])\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 🔍 Step 8: Make Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 🔍 Step 9: Evaluate Model Performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\n✅ Model Training Completed!\")\n",
        "print(\"🎯 Model Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "cex66CnoRPhd",
        "outputId": "e649998d-1c88-4b1e-8e05-a3e51ee3dde9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            " age                    0\n",
            "admission_type         0\n",
            "diagnosis              0\n",
            "medications            0\n",
            "length_of_stay         0\n",
            "previous_admissions    0\n",
            "readmitted             0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-d3c7624ed016>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# 🔍 Step 6: Train-Test Split (Fix NaN issues in `y`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# 🔍 Step 7: Train XGBoost Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2870\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2872\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_common_namespace_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1907\u001b[0m         \"\"\"\n\u001b[1;32m   1908\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1909\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1910\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2318\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2319\u001b[0m                 \u001b[0;34m\"The least populated class in y has only 1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m                 \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/nagken/medpredictml/main/data/diabetic_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 🔍 Check the first few rows\n",
        "print(df.head())\n",
        "\n",
        "# 🔍 Check for missing values\n",
        "print(\"Missing values in each column:\\n\", df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ddm_ArW6RbGz",
        "outputId": "5fbef984-ee6a-4b44-c1c3-211c3f5b1c86"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
            "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
            "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
            "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
            "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
            "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
            "\n",
            "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
            "0                  6                        25                    1   \n",
            "1                  1                         1                    7   \n",
            "2                  1                         1                    7   \n",
            "3                  1                         1                    7   \n",
            "4                  1                         1                    7   \n",
            "\n",
            "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
            "0                 1  ...          No      No                   No   \n",
            "1                 3  ...          No      Up                   No   \n",
            "2                 2  ...          No      No                   No   \n",
            "3                 2  ...          No      Up                   No   \n",
            "4                 1  ...          No  Steady                   No   \n",
            "\n",
            "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
            "0                   No                        No                       No   \n",
            "1                   No                        No                       No   \n",
            "2                   No                        No                       No   \n",
            "3                   No                        No                       No   \n",
            "4                   No                        No                       No   \n",
            "\n",
            "   metformin-pioglitazone  change diabetesMed readmitted  \n",
            "0                      No      No          No         NO  \n",
            "1                      No      Ch         Yes        >30  \n",
            "2                      No      No         Yes         NO  \n",
            "3                      No      Ch         Yes         NO  \n",
            "4                      No      Ch         Yes         NO  \n",
            "\n",
            "[5 rows x 50 columns]\n",
            "Missing values in each column:\n",
            " encounter_id                    0\n",
            "patient_nbr                     0\n",
            "race                            0\n",
            "gender                          0\n",
            "age                             0\n",
            "weight                          0\n",
            "admission_type_id               0\n",
            "discharge_disposition_id        0\n",
            "admission_source_id             0\n",
            "time_in_hospital                0\n",
            "payer_code                      0\n",
            "medical_specialty               0\n",
            "num_lab_procedures              0\n",
            "num_procedures                  0\n",
            "num_medications                 0\n",
            "number_outpatient               0\n",
            "number_emergency                0\n",
            "number_inpatient                0\n",
            "diag_1                          0\n",
            "diag_2                          0\n",
            "diag_3                          0\n",
            "number_diagnoses                0\n",
            "max_glu_serum               96420\n",
            "A1Cresult                   84748\n",
            "metformin                       0\n",
            "repaglinide                     0\n",
            "nateglinide                     0\n",
            "chlorpropamide                  0\n",
            "glimepiride                     0\n",
            "acetohexamide                   0\n",
            "glipizide                       0\n",
            "glyburide                       0\n",
            "tolbutamide                     0\n",
            "pioglitazone                    0\n",
            "rosiglitazone                   0\n",
            "acarbose                        0\n",
            "miglitol                        0\n",
            "troglitazone                    0\n",
            "tolazamide                      0\n",
            "examide                         0\n",
            "citoglipton                     0\n",
            "insulin                         0\n",
            "glyburide-metformin             0\n",
            "glipizide-metformin             0\n",
            "glimepiride-pioglitazone        0\n",
            "metformin-rosiglitazone         0\n",
            "metformin-pioglitazone          0\n",
            "change                          0\n",
            "diabetesMed                     0\n",
            "readmitted                      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/nagken/medpredictml/main/data/patient_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 🔍 Step 1: Check for missing values\n",
        "print(\"Missing values in each column:\\n\", df.isnull().sum())\n",
        "\n",
        "# 🔍 Step 2: Handle missing values (Drop or Impute)\n",
        "df = df.dropna(subset=[\"readmitted\"])  # Drop rows with missing target variable\n",
        "\n",
        "# 🔍 Step 3: Feature Engineering - Convert categorical variables\n",
        "categorical_cols = [\"admission_type\", \"diagnosis\", \"medications\"]\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "encoded_features = encoder.fit_transform(df[categorical_cols])\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out())\n",
        "\n",
        "# 🔍 Step 4: Standardize numerical features\n",
        "numerical_cols = [\"age\", \"length_of_stay\", \"previous_admissions\"]\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(df[numerical_cols])\n",
        "scaled_df = pd.DataFrame(scaled_features, columns=numerical_cols)\n",
        "\n",
        "# 🔍 Step 5: Prepare final dataset\n",
        "X = pd.concat([scaled_df, encoded_df], axis=1)\n",
        "y = df[\"readmitted\"].astype(int)  # Convert target variable to integer\n",
        "\n",
        "# 🔍 Step 6: Train-Test Split (Fix NaN issues in `y`)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 🔍 Step 7: Train XGBoost Model\n",
        "model = XGBClassifier(eval_metric='logloss', scale_pos_weight=y_train.value_counts()[0] / y_train.value_counts()[1])\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 🔍 Step 8: Make Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 🔍 Step 9: Evaluate Model Performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\n✅ Model Training Completed!\")\n",
        "print(\"🎯 Model Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "1k4GtFT0RjfH",
        "outputId": "b0b32c33-66db-4710-931a-243a2c0fa304"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            " age                    0\n",
            "admission_type         0\n",
            "diagnosis              0\n",
            "medications            0\n",
            "length_of_stay         0\n",
            "previous_admissions    0\n",
            "readmitted             0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-d3c7624ed016>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# 🔍 Step 6: Train-Test Split (Fix NaN issues in `y`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# 🔍 Step 7: Train XGBoost Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2870\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2872\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_common_namespace_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1907\u001b[0m         \"\"\"\n\u001b[1;32m   1908\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1909\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1910\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2318\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2319\u001b[0m                 \u001b[0;34m\"The least populated class in y has only 1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m                 \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# 📌 Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/nagken/medpredictml/main/data/patient_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 🔍 Step 1: Check for missing values\n",
        "print(\"Missing values in each column:\\n\", df.isnull().sum())\n",
        "\n",
        "# 🔍 Step 2: Convert categorical `readmitted` column to numeric (Binary Classification)\n",
        "df[\"readmitted\"] = df[\"readmitted\"].astype(int)  # Ensure it's an integer\n",
        "\n",
        "# 🔍 Step 3: Ensure `readmitted` has more than 1 instance per class\n",
        "print(\"Class distribution in 'readmitted':\\n\", df[\"readmitted\"].value_counts())\n",
        "\n",
        "# 🔍 Fix for `ValueError`: Remove classes with only 1 instance\n",
        "df = df[df[\"readmitted\"].map(df[\"readmitted\"].value_counts()) > 1]\n",
        "\n",
        "# 📌 Step 4: Define Features (X) & Target (y)\n",
        "categorical_cols = [\"admission_type\", \"diagnosis\", \"medications\"]\n",
        "numerical_cols = [\"age\", \"length_of_stay\", \"previous_admissions\"]\n",
        "\n",
        "# 🔍 Encode categorical features\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "encoded_features = encoder.fit_transform(df[categorical_cols])\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out())\n",
        "\n",
        "# 🔍 Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(df[numerical_cols])\n",
        "scaled_df = pd.DataFrame(scaled_features, columns=numerical_cols)\n",
        "\n",
        "# 📌 Combine all features\n",
        "X = pd.concat([scaled_df, encoded_df], axis=1)\n",
        "y = df[\"readmitted\"]\n",
        "\n",
        "# 🔍 Step 5: Fix Train-Test Split Issue\n",
        "if len(y.unique()) < 2:\n",
        "    raise ValueError(\"Not enough unique classes in `readmitted`. Check dataset balance.\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 📌 Step 6: Train XGBoost Model\n",
        "model = XGBClassifier(eval_metric='logloss', scale_pos_weight=y_train.value_counts()[0] / y_train.value_counts()[1])\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 📌 Step 7: Make Predictions & Evaluate Model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n✅ Patient Readmission Model Training Completed!\")\n",
        "print(\"🎯 Model Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "2-blNBbfR9sG",
        "outputId": "c85ba68d-1715-479d-ae54-23eab57924ab"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            " age                    0\n",
            "admission_type         0\n",
            "diagnosis              0\n",
            "medications            0\n",
            "length_of_stay         0\n",
            "previous_admissions    0\n",
            "readmitted             0\n",
            "dtype: int64\n",
            "Class distribution in 'readmitted':\n",
            " readmitted\n",
            "1    2\n",
            "0    1\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Not enough unique classes in `readmitted`. Check dataset balance.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-4b9f3716233a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# 🔍 Step 5: Fix Train-Test Split Issue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not enough unique classes in `readmitted`. Check dataset balance.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Not enough unique classes in `readmitted`. Check dataset balance."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# 📌 Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/nagken/medpredictml/main/data/patient_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 🔍 Step 1: Check for missing values\n",
        "print(\"Missing values in each column:\\n\", df.isnull().sum())\n",
        "\n",
        "# 🔍 Step 2: Convert `readmitted` column to integer\n",
        "df[\"readmitted\"] = df[\"readmitted\"].astype(int)\n",
        "\n",
        "# 🔍 Step 3: Check Class Distribution\n",
        "print(\"\\nClass distribution in 'readmitted':\\n\", df[\"readmitted\"].value_counts())\n",
        "\n",
        "# 🔍 Fix: Ensure at least 10 instances per class\n",
        "min_class_size = 10\n",
        "if df[\"readmitted\"].value_counts().min() < min_class_size:\n",
        "    print(\"\\n🚨 Not enough data for training! Adding synthetic samples...\\n\")\n",
        "\n",
        "    # Duplicate minority class\n",
        "    df = df.append(df[df[\"readmitted\"] == 0].sample(min_class_size, replace=True))\n",
        "    df = df.append(df[df[\"readmitted\"] == 1].sample(min_class_size, replace=True))\n",
        "\n",
        "# 🔍 Step 4: Define Features (X) & Target (y)\n",
        "categorical_cols = [\"admission_type\", \"diagnosis\", \"medications\"]\n",
        "numerical_cols = [\"age\", \"length_of_stay\", \"previous_admissions\"]\n",
        "\n",
        "# 🔍 Encode categorical features\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "encoded_features = encoder.fit_transform(df[categorical_cols])\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out())\n",
        "\n",
        "# 🔍 Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(df[numerical_cols])\n",
        "scaled_df = pd.DataFrame(scaled_features, columns=numerical_cols)\n",
        "\n",
        "# 📌 Combine all features\n",
        "X = pd.concat([scaled_df, encoded_df], axis=1)\n",
        "y = df[\"readmitted\"]\n",
        "\n",
        "# 🔍 Step 5: Fix Train-Test Split Issue\n",
        "if len(y.unique()) < 2:\n",
        "    raise ValueError(\"🚨 Not enough unique classes in `readmitted`. Check dataset balance.\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 📌 Step 6: Train XGBoost Model\n",
        "model = XGBClassifier(eval_metric='logloss')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 📌 Step 7: Make Predictions & Evaluate Model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n✅ Patient Readmission Model Training Completed!\")\n",
        "print(\"🎯 Model Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "syX1HeHGSswc",
        "outputId": "0d7e41a3-03e4-488d-f1e4-0f857fe2957f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            " age                    0\n",
            "admission_type         0\n",
            "diagnosis              0\n",
            "medications            0\n",
            "length_of_stay         0\n",
            "previous_admissions    0\n",
            "readmitted             0\n",
            "dtype: int64\n",
            "\n",
            "Class distribution in 'readmitted':\n",
            " readmitted\n",
            "1    2\n",
            "0    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "🚨 Not enough data for training! Adding synthetic samples...\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'append'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-615961ff29e3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Duplicate minority class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"readmitted\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_class_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"readmitted\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_class_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns (if needed)\n",
        "df = df.drop(columns=[\"encounter_id\", \"patient_nbr\"], errors=\"ignore\")  # These don't impact prediction\n",
        "\n",
        "# Replace \"?\" with NaN for proper missing value handling\n",
        "df.replace(\"?\", np.nan, inplace=True)\n",
        "\n",
        "# 🔍 Drop rows where the target column `readmitted` is missing\n",
        "df = df.dropna(subset=[\"readmitted\"])\n",
        "\n",
        "# 🔍 Encode target variable (`readmitted` as binary: 1 = readmitted, 0 = not readmitted)\n",
        "df[\"readmitted\"] = df[\"readmitted\"].apply(lambda x: 1 if x in [\"<30\", \">30\"] else 0)\n"
      ],
      "metadata": {
        "id": "2-k8OjZES2hI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select categorical & numerical features\n",
        "categorical_cols = [\"race\", \"gender\", \"admission_type_id\", \"discharge_disposition_id\", \"admission_source_id\"]\n",
        "numerical_cols = [\"age\", \"time_in_hospital\", \"num_lab_procedures\", \"num_medications\", \"number_diagnoses\"]\n",
        "\n",
        "# One-Hot Encode Categorical Columns\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "encoded_features = encoder.fit_transform(df[categorical_cols])\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out())\n",
        "\n",
        "# Standardize Numerical Features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(df[numerical_cols])\n",
        "scaled_df = pd.DataFrame(scaled_features, columns=numerical_cols)\n",
        "\n",
        "# Combine Processed Features\n",
        "X = pd.concat([scaled_df, encoded_df], axis=1)\n",
        "y = df[\"readmitted\"].astype(int)  # Convert target variable to integer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "gnnd9nuES69p",
        "outputId": "850a9e04-fc03-40af-be89-f15ea001ce88"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['race', 'gender', 'admission_type_id', 'discharge_disposition_id',\\n       'admission_source_id'],\\n      dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-d11e11f5babf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# One-Hot Encode Categorical Columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mencoded_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategorical_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mencoded_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['race', 'gender', 'admission_type_id', 'discharge_disposition_id',\\n       'admission_source_id'],\\n      dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 Step 1: Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# 📌 Step 2: Load Dataset\n",
        "url = \"https://raw.githubusercontent.com/nagken/medpredictml/main/data/diabetic_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 🔍 Check for missing values\n",
        "print(\"Missing values in each column:\\n\", df.isnull().sum())\n",
        "\n",
        "# 📌 Step 3: Preprocessing & Handling Missing Data\n",
        "df = df.drop(columns=[\"encounter_id\", \"patient_nbr\"], errors=\"ignore\")  # Drop unnecessary columns\n",
        "df.replace(\"?\", np.nan, inplace=True)  # Convert \"?\" to NaN\n",
        "df = df.dropna(subset=[\"readmitted\"])  # Drop rows with missing target column\n",
        "\n",
        "# 🔍 Encode `readmitted` as binary (1 = readmitted, 0 = not readmitted)\n",
        "df[\"readmitted\"] = df[\"readmitted\"].apply(lambda x: 1 if x in [\"<30\", \">30\"] else 0)\n",
        "\n",
        "# 📌 Step 4: Feature Engineering\n",
        "categorical_cols = [\"race\", \"gender\", \"admission_type_id\", \"discharge_disposition_id\", \"admission_source_id\"]\n",
        "numerical_cols = [\"age\", \"time_in_hospital\", \"num_lab_procedures\", \"num_medications\", \"number_diagnoses\"]\n",
        "\n",
        "# One-Hot Encoding for Categorical Variables\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "encoded_features = encoder.fit_transform(df[categorical_cols])\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out())\n",
        "\n",
        "# Standardize Numerical Features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(df[numerical_cols])\n",
        "scaled_df = pd.DataFrame(scaled_features, columns=numerical_cols)\n",
        "\n",
        "# Combine Processed Features\n",
        "X = pd.concat([scaled_df, encoded_df], axis=1)\n",
        "y = df[\"readmitted\"].astype(int)\n",
        "\n",
        "# 📌 Step 5: Train & Evaluate XGBoost Model\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Train XGBoost Classifier with class imbalance handling\n",
        "model = XGBClassifier(eval_metric='logloss', scale_pos_weight=y_train.value_counts()[0] / y_train.value_counts()[1])\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate Model Performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\n✅ Diabetes Model Training Completed!\")\n",
        "print(\"🎯 Model Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wW_xllxJT3Jj",
        "outputId": "03492a44-2b87-4413-f164-5968cd8a8153"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            " encounter_id                    0\n",
            "patient_nbr                     0\n",
            "race                            0\n",
            "gender                          0\n",
            "age                             0\n",
            "weight                          0\n",
            "admission_type_id               0\n",
            "discharge_disposition_id        0\n",
            "admission_source_id             0\n",
            "time_in_hospital                0\n",
            "payer_code                      0\n",
            "medical_specialty               0\n",
            "num_lab_procedures              0\n",
            "num_procedures                  0\n",
            "num_medications                 0\n",
            "number_outpatient               0\n",
            "number_emergency                0\n",
            "number_inpatient                0\n",
            "diag_1                          0\n",
            "diag_2                          0\n",
            "diag_3                          0\n",
            "number_diagnoses                0\n",
            "max_glu_serum               96420\n",
            "A1Cresult                   84748\n",
            "metformin                       0\n",
            "repaglinide                     0\n",
            "nateglinide                     0\n",
            "chlorpropamide                  0\n",
            "glimepiride                     0\n",
            "acetohexamide                   0\n",
            "glipizide                       0\n",
            "glyburide                       0\n",
            "tolbutamide                     0\n",
            "pioglitazone                    0\n",
            "rosiglitazone                   0\n",
            "acarbose                        0\n",
            "miglitol                        0\n",
            "troglitazone                    0\n",
            "tolazamide                      0\n",
            "examide                         0\n",
            "citoglipton                     0\n",
            "insulin                         0\n",
            "glyburide-metformin             0\n",
            "glipizide-metformin             0\n",
            "glimepiride-pioglitazone        0\n",
            "metformin-rosiglitazone         0\n",
            "metformin-pioglitazone          0\n",
            "change                          0\n",
            "diabetesMed                     0\n",
            "readmitted                      0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: '[0-10)'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2ff58be43dcd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Standardize Numerical Features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mscaled_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumerical_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mscaled_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumerical_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \"\"\"\n\u001b[1;32m    929\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[0-10)'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/nagken/medpredictml/main/data/diabetic_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(columns=[\"encounter_id\", \"patient_nbr\"], errors=\"ignore\")\n",
        "\n",
        "# Replace \"?\" with NaN for proper handling\n",
        "df.replace(\"?\", np.nan, inplace=True)\n",
        "\n",
        "# Drop columns with excessive missing values\n",
        "df = df.drop(columns=[\"max_glu_serum\", \"A1Cresult\"], errors=\"ignore\")\n",
        "\n",
        "# Convert `age` from ranges like \"[10-20)\" to numerical midpoints\n",
        "age_mapping = {\n",
        "    \"[0-10)\": 5, \"[10-20)\": 15, \"[20-30)\": 25, \"[30-40)\": 35, \"[40-50)\": 45,\n",
        "    \"[50-60)\": 55, \"[60-70)\": 65, \"[70-80)\": 75, \"[80-90)\": 85, \"[90-100)\": 95\n",
        "}\n",
        "df[\"age\"] = df[\"age\"].map(age_mapping)\n",
        "\n",
        "# Drop rows where target column `readmitted` is missing\n",
        "df = df.dropna(subset=[\"readmitted\"])\n",
        "\n",
        "# Encode target variable (`readmitted` as binary: 1 = readmitted, 0 = not readmitted)\n",
        "df[\"readmitted\"] = df[\"readmitted\"].apply(lambda x: 1 if x in [\"<30\", \">30\"] else 0)\n",
        "\n",
        "# Define categorical and numerical columns\n",
        "categorical_cols = [\"race\", \"gender\", \"admission_type_id\", \"discharge_disposition_id\", \"admission_source_id\"]\n",
        "numerical_cols = [\"age\", \"time_in_hospital\", \"num_lab_procedures\", \"num_medications\", \"number_diagnoses\"]\n",
        "\n",
        "# One-Hot Encode Categorical Variables\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "encoded_features = encoder.fit_transform(df[categorical_cols])\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out())\n",
        "\n",
        "# Standardize Numerical Features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(df[numerical_cols])\n",
        "scaled_df = pd.DataFrame(scaled_features, columns=numerical_cols)\n",
        "\n",
        "# Combine Processed Features\n",
        "X = pd.concat([scaled_df, encoded_df], axis=1)\n",
        "y = df[\"readmitted\"].astype(int)\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Train XGBoost Classifier with class imbalance handling\n",
        "model = XGBClassifier(eval_metric='logloss', scale_pos_weight=y_train.value_counts()[0] / y_train.value_counts()[1])\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate Model Performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6Fj9eq8Wpsk",
        "outputId": "926f750f-556f-4ddc-b757-796ed78c3105"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.5945760047165176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Load dataset\n",
        "url = \"https://raw.githubusercontent.com/nagken/medpredictml/main/data/diabetic_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(columns=[\"encounter_id\", \"patient_nbr\"], errors=\"ignore\")\n",
        "\n",
        "# Replace \"?\" with NaN\n",
        "df.replace(\"?\", np.nan, inplace=True)\n",
        "\n",
        "# Drop columns with excessive missing values\n",
        "df = df.drop(columns=[\"max_glu_serum\", \"A1Cresult\"], errors=\"ignore\")\n",
        "\n",
        "# Convert `age` from categorical ranges to numerical values\n",
        "age_mapping = {\n",
        "    \"[0-10)\": 5, \"[10-20)\": 15, \"[20-30)\": 25, \"[30-40)\": 35, \"[40-50)\": 45,\n",
        "    \"[50-60)\": 55, \"[60-70)\": 65, \"[70-80)\": 75, \"[80-90)\": 85, \"[90-100)\": 95\n",
        "}\n",
        "df[\"age\"] = df[\"age\"].map(age_mapping)\n",
        "\n",
        "# Drop rows where target column `readmitted` is missing\n",
        "df = df.dropna(subset=[\"readmitted\"])\n",
        "\n",
        "# Encode target variable (`readmitted` as binary: 1 = readmitted, 0 = not readmitted)\n",
        "df[\"readmitted\"] = df[\"readmitted\"].apply(lambda x: 1 if x in [\"<30\", \">30\"] else 0)\n",
        "\n",
        "# Define categorical and numerical columns\n",
        "categorical_cols = [\"race\", \"gender\", \"admission_type_id\", \"discharge_disposition_id\", \"admission_source_id\"]\n",
        "numerical_cols = [\"age\", \"time_in_hospital\", \"num_lab_procedures\", \"num_medications\", \"number_diagnoses\"]\n",
        "\n",
        "# One-Hot Encode Categorical Variables\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "encoded_features = encoder.fit_transform(df[categorical_cols])\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out())\n",
        "\n",
        "# Standardize Numerical Features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(df[numerical_cols])\n",
        "scaled_df = pd.DataFrame(scaled_features, columns=numerical_cols)\n",
        "\n",
        "# Combine Processed Features\n",
        "X = pd.concat([scaled_df, encoded_df], axis=1)\n",
        "y = df[\"readmitted\"].astype(int)\n",
        "\n",
        "# Handle class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Hyperparameter tuning for XGBoost\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'scale_pos_weight': [1, y_train.value_counts()[0] / y_train.value_counts()[1]]\n",
        "}\n",
        "\n",
        "xgb = XGBClassifier(eval_metric='logloss')\n",
        "grid_search = GridSearchCV(xgb, param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Train the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate Model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Optimized Model Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv6qAVBsXK-q",
        "outputId": "5a8c3f16-8176-492e-a04e-1ba91be0a802"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
            "Optimized Model Accuracy: 0.6239405814271394\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.60      0.61     10997\n",
            "           1       0.62      0.65      0.63     10949\n",
            "\n",
            "    accuracy                           0.62     21946\n",
            "   macro avg       0.62      0.62      0.62     21946\n",
            "weighted avg       0.62      0.62      0.62     21946\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/nagken/medpredictml/main/data/diabetic_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(columns=[\"encounter_id\", \"patient_nbr\"], errors=\"ignore\")\n",
        "\n",
        "# Replace \"?\" with NaN\n",
        "df.replace(\"?\", np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing target values\n",
        "df = df.dropna(subset=[\"readmitted\"])\n",
        "\n",
        "# Encode target variable\n",
        "df[\"readmitted\"] = df[\"readmitted\"].apply(lambda x: 1 if x in [\"<30\", \">30\"] else 0)\n",
        "\n",
        "# Define categorical and numerical features\n",
        "categorical_cols = [\"race\", \"gender\", \"admission_type_id\", \"discharge_disposition_id\", \"admission_source_id\"]\n",
        "numerical_cols = [\"age\", \"time_in_hospital\", \"num_lab_procedures\", \"num_medications\", \"number_diagnoses\"]\n",
        "\n",
        "# One-Hot Encoding\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "encoded_features = encoder.fit_transform(df[categorical_cols])\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out())\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(df[numerical_cols])\n",
        "scaled_df = pd.DataFrame(scaled_features, columns=numerical_cols)\n",
        "\n",
        "# Combine processed features\n",
        "X = pd.concat([scaled_df, encoded_df], axis=1)\n",
        "y = df[\"readmitted\"].astype(int)\n",
        "\n",
        "# Apply SMOTE to balance the classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
        "\n",
        "# Train XGBoost Classifier\n",
        "model = XGBClassifier(eval_metric='logloss')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Model Evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy after SMOTE:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "fV6FOKgUZGm-",
        "outputId": "6868fa73-3b7d-4fa0-ffa4-0fe94bd60e8e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: '[0-10)'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-823814567a90>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Standardize numerical features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mscaled_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumerical_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mscaled_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumerical_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \"\"\"\n\u001b[1;32m    929\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[0-10)'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/nagken/medpredictml/main/data/diabetic_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Display first few rows\n",
        "print(\"Sample Data:\\n\", df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values in each column:\\n\", df.isnull().sum())\n",
        "\n",
        "# 🔹 Step 1: Drop unnecessary columns\n",
        "df = df.drop(columns=[\"encounter_id\", \"patient_nbr\"], errors=\"ignore\")  # These IDs are not useful for prediction\n",
        "\n",
        "# 🔹 Step 2: Convert \"?\" values to NaN\n",
        "df.replace(\"?\", np.nan, inplace=True)\n",
        "\n",
        "# 🔹 Step 3: Handle Age Column (Convert Categorical Ranges to Numeric Midpoints)\n",
        "age_mapping = {\n",
        "    \"[0-10)\": 5, \"[10-20)\": 15, \"[20-30)\": 25, \"[30-40)\": 35, \"[40-50)\": 45,\n",
        "    \"[50-60)\": 55, \"[60-70)\": 65, \"[70-80)\": 75, \"[80-90)\": 85, \"[90-100)\": 95\n",
        "}\n",
        "df[\"age\"] = df[\"age\"].map(age_mapping)\n",
        "\n",
        "# 🔹 Step 4: Handle Missing Data\n",
        "# Drop rows where `readmitted` is missing (our target variable)\n",
        "df = df.dropna(subset=[\"readmitted\"])\n",
        "\n",
        "# Encode the target variable (`readmitted`: 1 if readmitted, 0 if not)\n",
        "df[\"readmitted\"] = df[\"readmitted\"].apply(lambda x: 1 if x in [\"<30\", \">30\"] else 0)\n",
        "\n",
        "# 🔹 Step 5: Feature Engineering\n",
        "categorical_cols = [\"race\", \"gender\", \"admission_type_id\", \"discharge_disposition_id\", \"admission_source_id\"]\n",
        "numerical_cols = [\"age\", \"time_in_hospital\", \"num_lab_procedures\", \"num_medications\", \"number_diagnoses\"]\n",
        "\n",
        "# One-Hot Encode Categorical Features\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "encoded_features = encoder.fit_transform(df[categorical_cols])\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out())\n",
        "\n",
        "# Standardize Numerical Features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(df[numerical_cols])\n",
        "scaled_df = pd.DataFrame(scaled_features, columns=numerical_cols)\n",
        "\n",
        "# Combine Processed Features\n",
        "X = pd.concat([scaled_df, encoded_df], axis=1)\n",
        "y = df[\"readmitted\"].astype(int)  # Convert target variable to integer\n",
        "\n",
        "# 🔹 Step 6: Handle Class Imbalance (Check Distribution)\n",
        "print(\"\\nClass distribution in 'readmitted':\\n\", y.value_counts())\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Handle Class Imbalance Using scale_pos_weight\n",
        "scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
        "\n",
        "# 🔹 Step 7: Train XGBoost Model\n",
        "model = XGBClassifier(eval_metric='logloss', scale_pos_weight=scale_pos_weight)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 🔹 Step 8: Make Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 🔹 Step 9: Evaluate Model Performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\nModel Accuracy:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6X3TRa5ZuQh",
        "outputId": "098b108c-d5b9-49a8-9e33-89c41bd76ab5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Data:\n",
            "    encounter_id  patient_nbr             race  gender      age weight  \\\n",
            "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
            "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
            "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
            "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
            "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
            "\n",
            "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
            "0                  6                        25                    1   \n",
            "1                  1                         1                    7   \n",
            "2                  1                         1                    7   \n",
            "3                  1                         1                    7   \n",
            "4                  1                         1                    7   \n",
            "\n",
            "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
            "0                 1  ...          No      No                   No   \n",
            "1                 3  ...          No      Up                   No   \n",
            "2                 2  ...          No      No                   No   \n",
            "3                 2  ...          No      Up                   No   \n",
            "4                 1  ...          No  Steady                   No   \n",
            "\n",
            "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
            "0                   No                        No                       No   \n",
            "1                   No                        No                       No   \n",
            "2                   No                        No                       No   \n",
            "3                   No                        No                       No   \n",
            "4                   No                        No                       No   \n",
            "\n",
            "   metformin-pioglitazone  change diabetesMed readmitted  \n",
            "0                      No      No          No         NO  \n",
            "1                      No      Ch         Yes        >30  \n",
            "2                      No      No         Yes         NO  \n",
            "3                      No      Ch         Yes         NO  \n",
            "4                      No      Ch         Yes         NO  \n",
            "\n",
            "[5 rows x 50 columns]\n",
            "\n",
            "Missing values in each column:\n",
            " encounter_id                    0\n",
            "patient_nbr                     0\n",
            "race                            0\n",
            "gender                          0\n",
            "age                             0\n",
            "weight                          0\n",
            "admission_type_id               0\n",
            "discharge_disposition_id        0\n",
            "admission_source_id             0\n",
            "time_in_hospital                0\n",
            "payer_code                      0\n",
            "medical_specialty               0\n",
            "num_lab_procedures              0\n",
            "num_procedures                  0\n",
            "num_medications                 0\n",
            "number_outpatient               0\n",
            "number_emergency                0\n",
            "number_inpatient                0\n",
            "diag_1                          0\n",
            "diag_2                          0\n",
            "diag_3                          0\n",
            "number_diagnoses                0\n",
            "max_glu_serum               96420\n",
            "A1Cresult                   84748\n",
            "metformin                       0\n",
            "repaglinide                     0\n",
            "nateglinide                     0\n",
            "chlorpropamide                  0\n",
            "glimepiride                     0\n",
            "acetohexamide                   0\n",
            "glipizide                       0\n",
            "glyburide                       0\n",
            "tolbutamide                     0\n",
            "pioglitazone                    0\n",
            "rosiglitazone                   0\n",
            "acarbose                        0\n",
            "miglitol                        0\n",
            "troglitazone                    0\n",
            "tolazamide                      0\n",
            "examide                         0\n",
            "citoglipton                     0\n",
            "insulin                         0\n",
            "glyburide-metformin             0\n",
            "glipizide-metformin             0\n",
            "glimepiride-pioglitazone        0\n",
            "metformin-rosiglitazone         0\n",
            "metformin-pioglitazone          0\n",
            "change                          0\n",
            "diabetesMed                     0\n",
            "readmitted                      0\n",
            "dtype: int64\n",
            "\n",
            "Class distribution in 'readmitted':\n",
            " readmitted\n",
            "0    54864\n",
            "1    46902\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Model Accuracy: 0.5945760047165176\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.52      0.58     10973\n",
            "           1       0.55      0.68      0.61      9381\n",
            "\n",
            "    accuracy                           0.59     20354\n",
            "   macro avg       0.60      0.60      0.59     20354\n",
            "weighted avg       0.61      0.59      0.59     20354\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE  # To handle class imbalance\n",
        "\n",
        "# Load dataset\n",
        "url = \"https://raw.githubusercontent.com/nagken/medpredictml/main/data/diabetic_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Step 1: Drop unnecessary columns\n",
        "df = df.drop(columns=[\"encounter_id\", \"patient_nbr\"], errors=\"ignore\")\n",
        "\n",
        "# Step 2: Handle Missing Values\n",
        "df.replace(\"?\", np.nan, inplace=True)\n",
        "\n",
        "# Drop max_glu_serum and A1Cresult (too many missing values)\n",
        "df = df.drop(columns=[\"max_glu_serum\", \"A1Cresult\"], errors=\"ignore\")\n",
        "\n",
        "# Fill missing categorical values with \"Unknown\"\n",
        "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
        "    df[col] = df[col].fillna(\"Unknown\")\n",
        "\n",
        "# Step 3: Convert Categorical Age to Numeric Midpoints\n",
        "age_mapping = {\n",
        "    \"[0-10)\": 5, \"[10-20)\": 15, \"[20-30)\": 25, \"[30-40)\": 35, \"[40-50)\": 45,\n",
        "    \"[50-60)\": 55, \"[60-70)\": 65, \"[70-80)\": 75, \"[80-90)\": 85, \"[90-100)\": 95\n",
        "}\n",
        "df[\"age\"] = df[\"age\"].map(age_mapping)\n",
        "\n",
        "# Step 4: Encode Categorical Columns\n",
        "categorical_cols = [\"race\", \"gender\", \"admission_type_id\", \"discharge_disposition_id\", \"admission_source_id\",\n",
        "                    \"insulin\", \"change\", \"diabetesMed\"]\n",
        "\n",
        "# Convert \"No\", \"Steady\", \"Up\" to numerical values\n",
        "insulin_mapping = {\"No\": 0, \"Steady\": 1, \"Up\": 2, \"Down\": 3}\n",
        "df[\"insulin\"] = df[\"insulin\"].map(insulin_mapping)\n",
        "\n",
        "# Convert \"No\" / \"Ch\" in 'change' column\n",
        "df[\"change\"] = df[\"change\"].map({\"No\": 0, \"Ch\": 1})\n",
        "\n",
        "# Convert \"Yes\" / \"No\" in 'diabetesMed' column\n",
        "df[\"diabetesMed\"] = df[\"diabetesMed\"].map({\"No\": 0, \"Yes\": 1})\n",
        "\n",
        "# One-Hot Encode Other Categorical Variables\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "encoded_features = encoder.fit_transform(df[categorical_cols])\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out())\n",
        "\n",
        "# Step 5: Standardize Numerical Features\n",
        "numerical_cols = [\"age\", \"time_in_hospital\", \"num_lab_procedures\", \"num_medications\", \"number_diagnoses\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(df[numerical_cols])\n",
        "scaled_df = pd.DataFrame(scaled_features, columns=numerical_cols)\n",
        "\n",
        "# Step 6: Combine All Features\n",
        "X = pd.concat([scaled_df, encoded_df], axis=1)\n",
        "y = df[\"readmitted\"].apply(lambda x: 1 if x in [\"<30\", \">30\"] else 0)  # Convert target to binary (1 = Readmitted)\n",
        "\n",
        "# Handle Class Imbalance using SMOTE\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Step 7: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
        "\n",
        "# Step 8: Train Optimized XGBoost Model\n",
        "model = XGBClassifier(eval_metric='logloss', scale_pos_weight=y_train.value_counts()[0] / y_train.value_counts()[1])\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 9: Make Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 10: Evaluate Model Performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\nModel Accuracy:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTkCLIRTamNi",
        "outputId": "52f5ec38-08c7-4a13-8d40-e19410a92fab"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracy: 0.6279048573771986\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.61      0.62     10973\n",
            "           1       0.62      0.65      0.63     10973\n",
            "\n",
            "    accuracy                           0.63     21946\n",
            "   macro avg       0.63      0.63      0.63     21946\n",
            "weighted avg       0.63      0.63      0.63     21946\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PdTutqJ6cafm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}